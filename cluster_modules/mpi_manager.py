#!/usr/bin/env python3
"""
MPI Manager Module

Handles OpenMPI installation, configuration, and hostfile management for the cluster.

Features:
- OpenMPI installation via Homebrew
- Hostfile generation (standard, optimal, max)
- MCA parameter configuration
- Multi-node MPI testing
"""

import os
import subprocess
from pathlib import Path
from typing import List, Dict, Optional


class MPIManager:
    """Manages OpenMPI installation and configuration"""
    
    def __init__(self, master_ip: str, worker_ips: List[str], username: str, 
                 threads_config: Optional[Dict[str, int]] = None):
        """
        Initialize MPI Manager
        
        Args:
            master_ip: IP address of master node
            worker_ips: List of worker node IP addresses
            username: Username for cluster nodes
            threads_config: Dictionary mapping IP addresses to thread counts
        """
        self.master_ip = master_ip
        self.worker_ips = worker_ips
        self.all_ips = [master_ip] + worker_ips
        self.username = username
        self.threads_config = threads_config or {}
        self.openmpi_dir = Path.home() / '.openmpi'
    
    def install_openmpi(self, run_command_func, run_sudo_command_func, pkg_manager='apt-get'):
        """
        Install OpenMPI via Homebrew
        
        Args:
            run_command_func: Function to run shell commands
            run_sudo_command_func: Function to run sudo commands
            pkg_manager: Package manager (apt-get or dnf)
        """
        print("\n=== Installing OpenMPI ===")
        
        # Check if already installed
        result = run_command_func("brew list open-mpi", check=False)
        if result.returncode == 0:
            print("OpenMPI already installed")
            return
        
        # Install via Homebrew
        print("Installing OpenMPI via Homebrew...")
        run_command_func("brew install open-mpi")
        
        print("OpenMPI installed successfully")
    
    def generate_hostfiles(self):
        """Generate three types of MPI hostfiles"""
        print("\n=== Generating MPI Hostfiles ===")
        
        # Create .openmpi directory
        self.openmpi_dir.mkdir(exist_ok=True)
        
        # Generate three types of hostfiles
        self._generate_standard_hostfile()
        self._generate_optimal_hostfile()
        self._generate_max_hostfile()
        
        print(f"✓ Hostfiles created in {self.openmpi_dir}")
    
    def _generate_standard_hostfile(self):
        """Generate standard hostfile (4 slots per node)"""
        hostfile_path = self.openmpi_dir / 'hostfile'
        
        with open(hostfile_path, 'w') as f:
            f.write("# Standard MPI Hostfile\n")
            f.write("# 4 MPI processes per node (balanced MPI+OpenMP)\n\n")
            
            for ip in self.all_ips:
                f.write(f"{ip} slots=4\n")
        
        print(f"  ✓ Standard hostfile: {hostfile_path}")
    
    def _generate_optimal_hostfile(self):
        """Generate optimal hostfile (1 MPI process per node, max OpenMP threads)"""
        hostfile_path = self.openmpi_dir / 'hostfile_optimal'
        
        with open(hostfile_path, 'w') as f:
            f.write("# Optimal MPI Hostfile (Hybrid MPI+OpenMP)\n")
            f.write("# 1 MPI process per node, all cores for OpenMP threads\n")
            f.write("# Use with: export OMP_NUM_THREADS=<cores>\n\n")
            
            for ip in self.all_ips:
                threads = self.threads_config.get(ip, 16)
                f.write(f"{ip} slots=1 # {threads} OpenMP threads available\n")
        
        print(f"  ✓ Optimal hostfile: {hostfile_path}")
    
    def _generate_max_hostfile(self):
        """Generate maximum MPI hostfile (all cores as MPI processes)"""
        hostfile_path = self.openmpi_dir / 'hostfile_max'
        
        with open(hostfile_path, 'w') as f:
            f.write("# Maximum MPI Hostfile\n")
            f.write("# All cores as MPI processes (pure MPI, minimal OpenMP)\n\n")
            
            for ip in self.all_ips:
                threads = self.threads_config.get(ip, 16)
                f.write(f"{ip} slots={threads}\n")
        
        print(f"  ✓ Maximum MPI hostfile: {hostfile_path}")
    
    def configure_mca_parameters(self, run_command_func):
        """Configure MCA (Modular Component Architecture) parameters"""
        print("\n=== Configuring MPI MCA Parameters ===")
        
        # Create MCA config file
        mca_config = self.openmpi_dir / 'mca-params.conf'
        
        # Detect network configuration
        network_config = self._detect_network_config(run_command_func)
        
        with open(mca_config, 'w') as f:
            f.write("# OpenMPI MCA Parameters\n")
            f.write("# Auto-generated by cluster_setup.py\n\n")
            
            # BTL (Byte Transfer Layer) configuration
            f.write("# TCP interface for multi-node communication\n")
            f.write(f"btl_tcp_if_include = {network_config['interface']}\n\n")
            
            # OOB (Out-of-Band) configuration for PRRTE
            f.write("# Out-of-band TCP communication\n")
            f.write(f"oob_tcp_if_include = {network_config['interface']}\n")
            f.write("oob_tcp_port_min_v4 = 50100\n")
            f.write("oob_tcp_port_range_v4 = 100\n\n")
            
            # Performance tuning
            f.write("# Performance tuning\n")
            f.write("btl_tcp_eager_limit = 32768\n")
            f.write("btl_tcp_max_send_size = 131072\n\n")
        
        print(f"✓ MCA parameters configured: {mca_config}")
        return str(mca_config)
    
    def _detect_network_config(self, run_command_func) -> Dict[str, str]:
        """Detect network interface configuration"""
        # Try to detect the main network interface
        result = run_command_func("ip route show default", check=False)
        
        if result.returncode == 0 and result.stdout:
            # Extract interface from default route
            parts = result.stdout.split()
            if 'dev' in parts:
                idx = parts.index('dev')
                if idx + 1 < len(parts):
                    interface = parts[idx + 1]
                    return {'interface': interface}
        
        # Fallback to eth0 or detect first non-loopback interface
        result = run_command_func("ip -o link show | awk -F': ' '{print $2}'", check=False)
        if result.returncode == 0:
            interfaces = [i.strip() for i in result.stdout.split('\n') if i.strip() and i.strip() != 'lo']
            if interfaces:
                return {'interface': interfaces[0]}
        
        # Final fallback
        return {'interface': 'eth0'}
    
    def distribute_mca_config(self, password: str, username: str):
        """Distribute MCA configuration to all cluster nodes"""
        if not password:
            print("⚠ Password required for MCA config distribution")
            return
        
        print("\n=== Distributing MCA Configuration to All Nodes ===")
        
        mca_config = self.openmpi_dir / 'mca-params.conf'
        if not mca_config.exists():
            print("⚠ MCA config file not found, skipping distribution")
            return
        
        # Get local IPs to skip current node
        try:
            import socket
            result = subprocess.run(['ip', 'addr'], capture_output=True, text=True)
            import re
            local_ips = re.findall(r'inet\s+(\d+\.\d+\.\d+\.\d+)', result.stdout)
        except:
            local_ips = []
        
        other_nodes = [ip for ip in self.all_ips if ip not in local_ips]
        
        for node_ip in other_nodes:
            print(f"\n→ Distributing to {node_ip}...")
            
            # Create .openmpi directory on remote node
            mkdir_cmd = f"sshpass -p '{password}' ssh -o StrictHostKeyChecking=no {username}@{node_ip} 'mkdir -p ~/.openmpi'"
            subprocess.run(mkdir_cmd, shell=True, capture_output=True)
            
            # Copy MCA config
            scp_cmd = f"sshpass -p '{password}' scp -o StrictHostKeyChecking=no {mca_config} {username}@{node_ip}:~/.openmpi/"
            result = subprocess.run(scp_cmd, shell=True, capture_output=True)
            
            if result.returncode == 0:
                print(f"  ✓ MCA config copied to {node_ip}")
            else:
                print(f"  ⚠ Failed to copy MCA config to {node_ip}")
    
    def test_mpi_installation(self, run_command_func):
        """Test MPI installation with a simple program"""
        print("\n=== Testing MPI Installation ===")
        
        test_dir = Path('/tmp/mpi_test')
        test_dir.mkdir(exist_ok=True)
        
        # Create simple MPI test program
        test_program = test_dir / 'hello_mpi.c'
        with open(test_program, 'w') as f:
            f.write("""
#include <mpi.h>
#include <stdio.h>

int main(int argc, char** argv) {
    MPI_Init(&argc, &argv);
    
    int rank, size;
    MPI_Comm_rank(MPI_COMM_WORLD, &rank);
    MPI_Comm_size(MPI_COMM_WORLD, &size);
    
    char processor_name[MPI_MAX_PROCESSOR_NAME];
    int name_len;
    MPI_Get_processor_name(processor_name, &name_len);
    
    printf("Hello from rank %d/%d on %s\\n", rank, size, processor_name);
    
    MPI_Finalize();
    return 0;
}
""")
        
        # Compile
        compile_result = run_command_func(
            f"mpicc {test_program} -o {test_dir}/hello_mpi",
            check=False
        )
        
        if compile_result.returncode == 0:
            print("✓ MPI test program compiled successfully")
            
            # Run locally
            run_result = run_command_func(
                f"mpirun -np 2 {test_dir}/hello_mpi",
                check=False
            )
            
            if run_result.returncode == 0:
                print("✓ MPI test program executed successfully")
                print(f"  Output:\n{run_result.stdout}")
            else:
                print(f"⚠ MPI test execution failed: {run_result.stderr}")
        else:
            print(f"⚠ MPI compilation failed: {compile_result.stderr}")
    
    def get_mpi_info(self) -> Dict[str, str]:
        """Get OpenMPI installation information"""
        info = {}
        
        try:
            # Get version
            result = subprocess.run(['mpirun', '--version'], 
                                  capture_output=True, text=True, timeout=5)
            if result.returncode == 0:
                info['version'] = result.stdout.split('\n')[0]
            
            # Get installation prefix
            result = subprocess.run(['brew', '--prefix', 'open-mpi'],
                                  capture_output=True, text=True, timeout=5)
            if result.returncode == 0:
                info['prefix'] = result.stdout.strip()
            
            # Get binary locations
            for binary in ['mpirun', 'mpicc', 'mpic++']:
                result = subprocess.run(['which', binary],
                                      capture_output=True, text=True, timeout=5)
                if result.returncode == 0:
                    info[binary] = result.stdout.strip()
        
        except Exception as e:
            print(f"Warning: Could not get MPI info: {e}")
        
        return info


if __name__ == '__main__':
    # Simple test
    print("MPI Manager Module")
    print("==================")
    
    manager = MPIManager("192.168.1.10", ["192.168.1.11", "192.168.1.12"], "ubuntu")
    print(f"Manager initialized for {len(manager.all_ips)} nodes")
    
    info = manager.get_mpi_info()
    if info:
        print("\nMPI Installation Info:")
        for key, value in info.items():
            print(f"  {key}: {value}")
